"""
Description: å¯¹/utils/model.pyè„šæœ¬è¿›è¡Œæµ‹è¯•
    
-*- Encoding: UTF-8 -*-
@File     ï¼štest_model.py.py
@Author   ï¼šKing Songtao
@Time     ï¼š2025/2/22 ä¸‹åˆ1:51
@Contact  ï¼šking.songtao@gmail.com
"""
"""
Description: DeepSeekæ¨¡å‹æµ‹è¯•æ–‡ä»¶

-*- Encoding: UTF-8 -*-
@File     ï¼štest_model.py
@Author   ï¼šKing Songtao
@Time     ï¼š2025/2/22 ä¸‹åˆ12:52
@Contact  ï¼šking.songtao@gmail.com
"""

import os
import pytest
import torch
from typing import Optional
from utils.model import DeepSeek

# é…ç½®æµ‹è¯•æ¨¡å‹è·¯å¾„ï¼ˆè¯·æ›¿æ¢ä¸ºå®é™…å¯ç”¨çš„æ¨¡å‹è·¯å¾„ï¼‰
MODEL_PATH = os.environ.get(
    'DEEPSEEK_MODEL_PATH',
    'models/DeepSeek_R1_Distill_Qwen_32B'
)


# è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å¯ç”¨
def is_model_path_valid(path: str) -> bool:
    """
    æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æœ‰æ•ˆ

    :param path: æ¨¡å‹è·¯å¾„
    :return: è·¯å¾„æ˜¯å¦æœ‰æ•ˆ
    """
    return os.path.exists(path) and os.path.isdir(path)


@pytest.fixture(scope="module")
def deepseek_model():
    """
    æ¨¡å‹å®ä¾‹fixtureï¼Œç¡®ä¿æ¯ä¸ªæµ‹è¯•æ¨¡å—åªåŠ è½½ä¸€æ¬¡æ¨¡å‹
    """
    if not is_model_path_valid(MODEL_PATH):
        pytest.skip(f"æ— æ•ˆçš„æ¨¡å‹è·¯å¾„ï¼š{MODEL_PATH}")

    model = DeepSeek()
    model.load_model(MODEL_PATH)
    return model


def test_model_initialization():
    """
    æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–å‚æ•°
    """
    model = DeepSeek()

    # æ£€æŸ¥é»˜è®¤å‚æ•°
    assert model.max_token == 4096, "é»˜è®¤æœ€å¤§tokenæ•°ä¸æ­£ç¡®"
    assert model.temperature == 0.8, "é»˜è®¤æ¸©åº¦å‚æ•°ä¸æ­£ç¡®"
    assert model.top_p == 0.9, "é»˜è®¤top_på‚æ•°ä¸æ­£ç¡®"
    assert model.history == [], "åˆå§‹å¯¹è¯å†å²åº”ä¸ºç©º"


def test_load_model_invalid_path():
    """
    æµ‹è¯•åŠ è½½æ— æ•ˆæ¨¡å‹è·¯å¾„æ—¶çš„å¼‚å¸¸å¤„ç†
    """
    model = DeepSeek()
    invalid_paths = [
        "/path/to/non_existent_model",
        "",
        None
    ]

    for path in invalid_paths:
        with pytest.raises((FileNotFoundError, TypeError),
                           message=f"åº”å¯¹æ— æ•ˆè·¯å¾„ {path} æŠ›å‡ºå¼‚å¸¸"):
            model.load_model(path)


def test_model_inference(deepseek_model):
    """
    æµ‹è¯•æ¨¡å‹æ¨ç†åŸºæœ¬åŠŸèƒ½

    :param deepseek_model: æ¨¡å‹å®ä¾‹fixture
    """
    # æµ‹è¯•ç”¨ä¾‹
    test_prompts = [
        "ä½ å¥½",
        "ä»‹ç»ä¸‹äººå·¥æ™ºèƒ½",
        "è§£é‡Šé‡å­è®¡ç®—",
        "è®²ä¸€ä¸ªæœ‰è¶£çš„æ•…äº‹"
    ]

    for prompt in test_prompts:
        # æ¨ç†
        response = deepseek_model._call(prompt)

        # æ£€æŸ¥æ¨ç†ç»“æœ
        assert response is not None, f"prompt '{prompt}' æ¨ç†ç»“æœä¸åº”ä¸ºNone"
        assert isinstance(response, str), f"æ¨ç†ç»“æœåº”ä¸ºå­—ç¬¦ä¸²ï¼Œå®é™…ä¸º {type(response)}"
        assert len(response) > 0, f"prompt '{prompt}' æ¨ç†ç»“æœä¸åº”ä¸ºç©º"


def test_conversation_history(deepseek_model):
    """
    æµ‹è¯•å¯¹è¯å†å²ç®¡ç†

    :param deepseek_model: æ¨¡å‹å®ä¾‹fixture
    """
    # æ¸…ç©ºå†å²
    deepseek_model.history = []

    # å¤šè½®å¯¹è¯æµ‹è¯•
    conversation = [
        "ä½ å¥½ï¼Œä»Šå¤©å¿ƒæƒ…å¦‚ä½•ï¼Ÿ",
        "èƒ½ç»™æˆ‘è®²ä¸ªç¬‘è¯å—ï¼Ÿ",
        "æˆ‘ä»¬èŠç‚¹seriousçš„è¯é¢˜"
    ]

    responses = []
    for prompt in conversation:
        response = deepseek_model._call(prompt)
        responses.append(response)

    # æ£€æŸ¥å†å²è®°å½•
    assert len(deepseek_model.history) == len(conversation), "å¯¹è¯å†å²è®°å½•é•¿åº¦ä¸åŒ¹é…"

    # æ£€æŸ¥å†å²è®°å½•å†…å®¹
    for idx, (prompt, response) in enumerate(zip(conversation, responses)):
        assert deepseek_model.history[idx][1] == response, f"ç¬¬ {idx + 1} è½®å¯¹è¯å†å²è®°å½•ä¸æ­£ç¡®"


def test_stop_tokens(deepseek_model):
    """
    æµ‹è¯•åœæ­¢æ ‡è®°åŠŸèƒ½

    :param deepseek_model: æ¨¡å‹å®ä¾‹fixture
    """
    prompt = "ä»‹ç»äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹"
    stop_words = ["1990", "2000"]

    response = deepseek_model._call(prompt, stop=stop_words)

    # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢æ ‡è®°æˆªæ–­
    for word in stop_words:
        assert word not in response, f"å“åº”æœªæ­£ç¡®å¤„ç†åœæ­¢æ ‡è®°ï¼š{word}"


def test_performance(deepseek_model):
    """
    ç®€å•æ€§èƒ½æµ‹è¯•

    :param deepseek_model: æ¨¡å‹å®ä¾‹fixture
    """
    import time

    prompt = "ç”¨20å­—æ€»ç»“äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•"

    start_time = time.time()
    response = deepseek_model._call(prompt)
    inference_time = time.time() - start_time

    assert inference_time < 10, f"æ¨ç†æ—¶é—´è¿‡é•¿ï¼š{inference_time}ç§’"
    assert len(response) > 0, "æ€§èƒ½æµ‹è¯•æ¨ç†ç»“æœä¸ºç©º"


def test_special_characters(deepseek_model):
    """
    æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å¤„ç†

    :param deepseek_model: æ¨¡å‹å®ä¾‹fixture
    """
    special_prompts = [
        "ğŸ¤– äººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ã“ã‚“ã«ã¡ã¯ AI ã«ã¤ã„ã¦æ•™ãˆã¦",
        "   ç©ºç™½å¼€å¤´çš„prompt   ",
        "åŒ…å«\næ¢è¡Œ\nçš„prompt",
        "ğŸ’¡ ä¸ ğŸš€ ç»“åˆçš„æŠ€æœ¯"
    ]

    for prompt in special_prompts:
        response = deepseek_model._call(prompt)
        assert response is not None, f"ç‰¹æ®Špromptå¤„ç†å¤±è´¥ï¼š{prompt}"


# è¾¹ç•Œæµ‹è¯•
def test_edge_cases(deepseek_model):
    """
    è¾¹ç•Œæ¡ä»¶æµ‹è¯•

    :param deepseek_model: æ¨¡å‹å®ä¾‹fixture
    """
    # è¶…é•¿è¾“å…¥æµ‹è¯•
    long_prompt = "a" * 10000
    with pytest.raises(Exception):
        deepseek_model._call(long_prompt)

    # Noneè¾“å…¥æµ‹è¯•
    with pytest.raises(TypeError):
        deepseek_model._call(None)


# ä¸»å‡½æ•°ï¼Œç”¨äºç‹¬ç«‹è¿è¡Œæµ‹è¯•
if __name__ == "__main__":
    pytest.main([__file__])
