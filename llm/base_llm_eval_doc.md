# LLM模型评测系统说明文档

## 一、评测维度概览

### 1.1 总分计算权重分配

| 一级维度 | 权重 | 二级维度 | 权重 |
|---------|------|---------|------|
| 语言质量 | 30% | 流畅度 | 15% |
|         |      | 语法正确性 | 15% |
| 文本多样性 | 15% | Distinct-n scores | 5% |
|           |      | 词汇丰富度 | 5% |
|           |      | 信息熵 | 5% |
| 主题相关性 | 35% | 语义相关性 | 20% |
|           |      | 关键信息覆盖 | 15% |
| 一致性与连贯性 | 20% | 上下文一致性 | 10% |
|               |      | 句间连贯性 | 10% |

## 二、评测指标详解

### 2.1 语言质量评估

#### 2.1.1 流畅度评估
- **评估方法**：使用BERT模型计算困惑度(perplexity)
- **计算公式**：`score = 1 / (1 + perplexity)`
- **标准范围**：
  
  | 等级 | 困惑度范围 | 得分范围 |
  |------|------------|---------|
  | 优秀 | < 10 | > 0.9 |
  | 良好 | 10-20 | 0.8-0.9 |
  | 一般 | 20-30 | 0.7-0.8 |
  | 较差 | ≥ 30 | ≤ 0.7 |

#### 2.1.2 语法正确性
- **评估方法**：基于BERT的预测置信度
- **评分标准**：

  | 等级 | 置信度范围 |
  |------|------------|
  | 优秀 | > 0.9 |
  | 良好 | 0.8-0.9 |
  | 一般 | 0.7-0.8 |
  | 较差 | ≤ 0.7 |

### 2.2 文本多样性评估

#### 2.2.1 Distinct-n Scores
- **计算方法**：不同n-gram的比例
- **权重分配**：
  - Distinct-1：1.5%
  - Distinct-2：2%
  - Distinct-3：1.5%
- **评分标准**：

  | 等级 | 得分范围 |
  |------|---------|
  | 优秀 | > 0.8 |
  | 良好 | 0.6-0.8 |
  | 一般 | 0.4-0.6 |
  | 较差 | < 0.4 |

#### 2.2.2 词汇丰富度
- **计算方法**：Type-Token Ratio (TTR)
- **计算公式**：`不同词数 / 总词数`
- **评分标准**：

  | 等级 | TTR范围 |
  |------|---------|
  | 优秀 | > 0.7 |
  | 良好 | 0.5-0.7 |
  | 一般 | 0.3-0.5 |
  | 较差 | < 0.3 |

#### 2.2.3 信息熵
- **计算方法**：词频分布的Shannon熵
- **归一化处理**：`entropy / log2(词表大小)`
- **评分标准**：

  | 等级 | 熵值范围 |
  |------|---------|
  | 优秀 | > 0.8 |
  | 良好 | 0.6-0.8 |
  | 一般 | 0.4-0.6 |
  | 较差 | < 0.4 |

## 三、任务类型与参数建议

### 3.1 任务类型分类

| 任务类型 | 评估重点 | 权重调整 |
|---------|---------|----------|
| 知识解答 | 信息准确性、关键点覆盖率 | 提高主题相关性权重 |
| 开放讨论 | 观点完整性、论述逻辑性 | 提高连贯性权重 |
| 多轮对话 | 上下文理解、回复相关性 | 提高一致性权重 |
| 创意写作 | 文本多样性、表达流畅性 | 提高多样性权重 |
| 代码生成 | 语法正确性、功能完整性 | 提高语法正确性权重 |

### 3.2 参数调优建议

#### Temperature (温度)

| 任务类型 | 建议范围 |
|---------|---------|
| 知识类任务 | 0.3-0.5 |
| 创意类任务 | 0.7-0.9 |
| 对话类任务 | 0.5-0.7 |

#### Top_p (核采样)

| 任务类型 | 建议范围 |
|---------|---------|
| 知识类任务 | 0.7-0.8 |
| 创意类任务 | 0.9-1.0 |
| 对话类任务 | 0.8-0.9 |

#### Repetition Penalty (重复惩罚)

| 任务类型 | 建议范围 |
|---------|---------|
| 知识类任务 | 1.0-1.1 |
| 创意类任务 | 1.2-1.3 |
| 对话类任务 | 1.1-1.2 |

## 四、评测结果解读

### 4.1 分数区间说明

| 得分区间 | 等级 | 说明 |
|---------|------|------|
| 0.9-1.0 | 优秀 | 模型表现出色，可以直接应用 |
| 0.8-0.9 | 良好 | 模型表现稳定，小幅优化即可 |
| 0.7-0.8 | 一般 | 模型尚可使用，但需要改进 |
| < 0.7 | 较差 | 需要重点优化或调整 |

### 4.2 输出示例

```json
{
  "average_total_score": 0.85,
  "scores_by_category": {
    "knowledge_qa": 0.88,
    "open_discussion": 0.83,
    "multi_turn_dialogue": 0.85,
    "creative_writing": 0.87,
    "code_generation": 0.82
  },
  "detailed_scores": {
    "fluency": 0.89,
    "grammar": 0.92,
    "diversity": 0.85,
    "relevance": 0.87,
    "coverage": 0.83,
    "consistency": 0.84,
    "coherence": 0.82
  }
}
```

## 五、注意事项

### 5.1 评测建议
1. 进行多轮评测，每组参数至少测试3次
2. 关注不同任务类型的表现差异
3. 综合考虑各项指标，不要过分依赖单一指标
4. 定期更新测试用例，保持评测的时效性

### 5.2 资源要求
- BERT模型评估需要较大算力
- 建议使用GPU进行评测
- 评测前确保系统资源充足

### 5.3 使用说明
- 评测结果仅供参考
- 建议结合人工评估
- 持续收集用户反馈
- 根据实际应用场景调整权重